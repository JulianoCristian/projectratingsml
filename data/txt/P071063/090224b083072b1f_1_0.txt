 IEG
                                                                                             Report Number: ICRR14696

                 ICR Review
                 Independent Evaluation Group




       1. Project Data:                                      Date Posted: 03/31/2015

               Country: Kyrgyz Republic
             Project ID: P071063                                                 Appraisal              Actual
         Project Name: Governance                  Project Costs (US$M):                     10.21               7.98
                         Technical Assistance
                         Project
  L/C Number:                                        Loan/Credit (US$M):                      7.77               6.35
      Sector Board:      Public Sector               Cofinancing (US$M):
                         Governance
          Cofinanciers:                                Board Approval Date :                               05/15/2003
                                                                Closing Date:            12/31/2008        12/31/2013
         Sector(s):       Central government administration (100%)
         Theme(s):        Administrative and civil service reform (23%); Other public sector governance (22%); Other
                          accountability/anti-corruption (22%); Public expenditure; financial management and
                          procurement (22%); Poverty strategy; analysis and monitoring (11%)

Prepared by:              Reviewed by:           ICR Review                 Group:
                                                 Coordinator:
Malathi S.                Robert Mark Lacey      Lourdes N. Pagaran        IEGPS2
Jayawickrama

2. Project Objectives and Components:

a. Objectives:

    The objectives as stated in the Development Credit Agreement (DCA) (p. 13) are: to strengthen the Borrower’s
    institutional capacity to implement the measures under the Program and to assist with Treasury modernization.
    The Program referred to in the statement of objectives is that supported by the Governance Structural
    Adjustment Credit (GSAC). The Project Appraisal Document (PAD, p. 2) for this project (the Governance
    Technical Assistance Credit or GTAC) stated its objectives to be the same as those for the GSAC, namely “(i)
    improve transparency and responsiveness of the public sector and enhance the ability of external stakeholders to
    hold it accountable, and (ii) increase efficiency, effectiveness and accountability within the public sector.” A
    Corrigendum to the PAD (undated) was subsequently issued, aligning the GTAC’s objectives in that document
    with those in the DCA: “The objectives of the Project are to strengthen the Borrower’s institutional capacity to
    implement the measures under the Program outlined in the GSAC Program Document and to assist with the
    Treasury modernization.”
    This review is based on the statement of objectives in the DCA and in the PAD Corrigendum.



b.Were the project objectives/key associated outcome targets revised during implementation?
No

c. Components:

    There were three components:
   Component 1. Technical Assistance to Support Implementation of Reforms included in the GSAC (appraisal
   US$1.98 million, actual US$1.3 million) to provide consulting services, training and goods to carry out reforms
   supported by the GSAC. While other external partners were to provide grant assistance for some of the GSAC
   measures, the GTAC was to provide technical assistance (TA) for the remaining GSAC measures. GTAC
   assistance was to cover a longer time horizon (5 years) than that of the GSAC, in order to facilitate
   institutionalization and proper implementation of the policy measures. This component had six sub-components:
   (i) strengthen voice and participation through, inter alia, development of legal provisions and the establishment of
   a Government Public Information Center; (ii) improve transparency and value for money in public procurement
   through amendments to rules and processes and the carrying out of audits; (iii) improve service delivery in
   health, education and social protection; (iv) improve the effectiveness of the civil service through amended
   regulations, training, and making the Civil Service Management Agency (CSMA) fully operationa; (v) streamline
   the structure of government ministries and agencies; and (vi) refine the National Poverty Reduction Strategy
   (NPRS) and monitor and evaluate progress.

   Component 2: Modernization of the Treasury (appraisal US$6.37 million, actual US$5.52 million) to finance
   consulting services, goods and training for the modernization of Treasury operations through the implementation
   of a Treasury Management Information System (TMIS). The project was to provide assistance in: (a) preparation
   of user requirements, conceptual design of the system, system architecture and software and hardware
   specifications for the TMIS; (b) selection, procurement, adaptation and implementation of an off-the-shelf
   software package; (c) procurement and implementation of hardware and communication equipment; (d)
   development of the regulations for the implementation of the system; and (e) training of staff. The system was to
   be piloted in the Central Treasury and two or three pilot oblasts, before being replicated.

   Component 3: Project Management (appraisal US$0.66 million, actual US$1.12 million) to finance consulting
   services, equipment and training for the Project Management Group and Project Implementation Unit (PIU);
   surveys to collect data on key performance indicators and obtain stakeholder feedback; and project audits.
   During implementation, two sub-components were dropped, since the Government was able to access grant
   financing from other partners: i) streamlining the structure of Government ministries and agencies; and (ii)
   refining the NPRS and monitoring and evaluating progress. In addition, some activities were dropped from three
   sub-components that remained under Component 1 (strengthened voice and participation, improving service
   delivery in health and education, and improving the internal control environment).

d. Comments on Project Cost, Financing, Borrower Contribution, and Dates:

   Project Cost: The original project costs were estimated at US$10.21 million.. The final project costs were
   US$7.98 million (or 78 percent of the appraisal estimate). The difference was due mainly to the lack of
   completion of the Treasury Modernization activities.

   Financing: Of the IDA Credit of US$7.77 million, US$6.35 million was disbursed, The shortfall was due to contract
   termination under Component 2 (Treasury Modernization). The outstanding balance at closure (US$1.42 million)
   was canceled.

   Borrower Contribution. This was US$1.63 million, two-thirds of the appraisal estimate of US$2.44 million.
   Dates: There were four extensions of the closing date – on December 12, 2008, December 2010, February 14,
   2011, and May 28, 2013. All of them were due principally to delays in implementing the Treasury Modernization
   component. The project closed on December 31, 2013, five years behind the original five-and-a-half year
   schedule.


3. Relevance of Objectives & Design:

a. Relevance of Objectives:

   Substantial.

   The project's objectives are relevant to the Country Partnership Strategy, 2013-17, which includes a pillar on
   governance, and actions related to public administration and public service delivery. Improved governance is
   seen as essential to reducing poverty and promoting shared prosperity, and emphasizes making the state more
   accountable to citizens, and strengthening citizens' voice in actions of the state. The objectives were also
   relevant to the National Poverty Reduction Strategy (NPRS) at appraisal. The NPRS accorded high priority to
   measures that strengthened governance and accountability. The Bank and other Development Partners' Joint
   Country Support Strategy 2007–2010 (JCSS), which was closely aligned with the Government's development
   goals included reducing corruption, improving governance, and achieving effective public administration as one
   of its four pillars.


b. Relevance of Design:

   Modest.

   The relevance of design is assessed with respect to: (a) relevance of activities and policy areas to the objectives;
   and (b) the quality of the results framework. With respect to (a), there were clear links between the DPO and the
   outcomes the project expected to achieve, and the activities supported under its three components. To enhance
   the transparency and responsiveness of the public sector, it was critical to modernize the Treasury. The project
   components were well aligned with this objective. The Technical Assistance (TA) instrument was also
   appropriate to support the Governance and Structural Adjustment Credit.

   The results framework (RF) in the PAD (Annex 1, p. 27-31) was incomplete. Although GTAC was approved to
   support GSAC measures, there should have been a distinct results framework for the TA, for monitoring and
   attribution purposes. The RF in the PAD does not provide a clear causal chain or timeline linking GTAC activities
   and the carrying out of GSAC measures. There is also an absence of targets. We note that the operation was
   approved in 2003 when a full blown RF was not required, but this shortcoming could have been addressed during
   implementation, which took more than five years after its original closing date.


4. Achievement of Objectives (Efficacy):

   The degree of achievement of the PDO is assessed separately for the two objectives: (i) strengthening the
   Borrower's institutional capacity to implement GSAC program measures; and (ii) assisting with Treasury
   Modernization.

   Objective (i): Strengthening the Borrower 's institutional capacity to implement the measures under the program
   outlined in the GSAC document . Modest. The 2009 GSAC ICR concluded that the GSAC's Pillar 1 objectives on
   public sector transparency and responsiveness were essentially achieved. Pillar 1 of GSAC contained most of
   the areas covered under Component 1 of GTAC. However, the ICR outcome rating of the GSAC was ‘Moderately
   Unsatisfactory as at the time when it was written (2009) there was evidence of backtracking in areas such as
   de-politicizing the civil service, procurement, and overall transparency.

   GSAC Objective I .(i): Improving Personal Accountability of Political Officials and Civil Servants , and GSAC
   Objective I.(ii):Strengthening Voice and Participation . Both partially achieved . The Government adopted
   legislation on income and asset declarations of high state officials and their immediate family members. The
   cumulative data on income, liabilities and property are posted on the website of the State Personnel Service of
   the Kyrgyz Republic. In 2013, the compliance rate was 97.2 percent. According to the ICR, this information is not
   widely used by civil society as an instrument for strengthening accountability and integrity in the public sector as
   originally expected.
   GTAC supported the creation of databases of laws on access to public information, and a number of activities to
   facilitate citizens' access to public information. These included online access to the centralized database of the
   Ministry of Justice, the Public Information Center under the President's Administrative Unit, and the setting up of
   Public Steering Councils. The project sought to assess the impact of these reforms through periodic surveys of
   households, firms, and public officials to determine perceptions about transparency, responsiveness and integrity
   of the public sector. However, no baseline survey was undertaken and the periodic surveys were dropped without
   explanation (ICR, p. 23). There would also have been problems of attribution, since a wide range of factors
   outside the project would affect public perceptions. There is little further evidence presented on the outcomes of
   these reforms, and the indicators measure only inputs and outputs. The ICR presents an alternative source of
   data from the World Governance Indicators showing that ‘Voice and Accountability’ and ‘Government
   Effectiveness’ indicators were volatile over the project period (ICR, p. 25, Figure 1), and concludes that it is
   unclear what impact GTAC had, or could have had, on these indicators and on public perceptions more
   generally. Broader concerns related to political stability are likely to have been a more important determinant of
   public perceptions than any of the GTAC-supported governance reforms, even had these been successful.

   GSAC Objective II (i) b: Strengthening Accountability and Transparency in Budget Execution . Partially
   achieved. GTAC financed consultants to help the Treasury develop the Government Finance Statistics
   2001-compliant budget classification and provided technical support to implement the Medium Term Budgetary
   Framework (MTBF). The budget is now presented based on this new classification and is presented with two
years of historical data and indicative ceilings for the next three years. The linkages between the Medium Term
Expenditure Framework (MTEF) and the annual budget are, however, extremely weak. The project also
supported the development of the unified Chart of Accounts (CoA) and the creation of the Treasury Single
Account TSA. This contributed to the development of the Ministry of Finance’s (MoF’s) capability to submit
comprehensive budget execution reports to the Prime Minister’s Office, Parliament, the National Statistics
Committee, and other stakeholders within six months of budget execution. These reports are posted on the
official website of the MoF for public access. However, in the absence of an operational TMIS, data from regional
treasuries is still compiled from summary reports, and the MoF is unable to access all budget execution data at a
transaction level in real time. The ability to generate reliable management reports on its financial operations in
real time, employing contemporary information technology was viewed as essential to achieving a
well-functioning treasury (PAD, p. 73).

GTAC helped the Government to draft and pass the law on the Chart of Accounts (CoA) in June 2004 that
stipulated performance audits and an evaluation of the efficiency and effectiveness of public spending. Capacity
building for the Accounts Chamber was provided through an IDF grant. Parliament now receives the progress
report of the Accounts Chamber every September for the previous budget year as well as the opinion on the draft
Budget Law for the subsequent fiscal year. The results of the audit reports are widely discussed and referenced
in the mass media.

GSAC Objective II (iii): Improved transparency and value for money in public procurement . Not achieved. The
indicator to measure results of procurement audits of selected high value items was dropped. It is therefore
unclear what outcomes were achieved. Staff were trained in procurement rules, new tender documents were
developed and adopted, and the Government raised awareness of new procurement rules among business
circles. An internationally recognized company undertook an audit of selected items procured from the republican
budget and made recommendations for improving the procurement process to achieve greater value for money.
The ICR does not indicate whether the recommendations were applied.

GSAC Objective II (iv): Improved service delivery in health , education and social protection . Not achieved. The
ICR lists, 'improved financing of health and education services' as the indicator for this objective. Improved
financing is an input, which may not necessarily translate into 'improved service delivery'. GTAC-financed
technical assistance sought to strengthen financial management and to develop more equitable formulae for
grant transfers for health and education. However, in the health sector, the financing reforms were not
implemented owing to the transfer of responsibility for all health institutions to the republican budget. For
education, GTAC-supported capitation-based grants were adopted in March 2008, but there is no evidence
provided that service delivery improved.

GSAC Objective II (v): Enhanced Effectiveness of the Civil Service . Partially achieved. Of the five indicators
reported, three were not tracked -- number of applications for civil service positions, percentage increase in civil
service salaries, and percentage decrease in number of civil servants (ICR, p. 45). GTAC supported civil service
reforms that sought to (i) eliminate patronage by ministers and their appointees in designating civil servants, (ii)
introduce merit and rule based appointment and promotion, and (iii) improve security of tenure for professional
civil servants. Following the approval of the 2004 Civil Service Law (CSL), GTAC helped to establish the Civil
Service Agency (CSA). The project financed advisory services developing a rule based system of appointments
and dismissals which separated political appointees from career civil servants and introduced State Secretaries
to head the permanent civil service in all ministries. During the revolution of March 2005, when there was
considerable turnover of political appointees, the newly established CSA managed to protect some professional
civil servants from illegal dismissals. The system of appointments was significantly improved -- the reported
number of appointments made through due process was close to 100 percent by 2009, compared with about 50
percent at the end of 2005. Most ministries now have State Secretaries who manage human resources and
budgets to meet their objectives.

Objective (ii): Assist with the Treasury Modernization . Negligible
Only one indicator was related to this objective: Improved access, reliability and timeliness of information about
budget execution, to public officials and civil society . There were no intermediate indicators with which to track
progress in implementing Treasury modernization. It was originally intended that the TMIS would be piloted in
the Central Treasury and two or three pilot oblasts, before being rolled out to all eight oblasts and 57 regions
Treasury offices. However, procurement issues and the political events of 2005 delayed TMIS development
during the first three years of implementation (2003-2006). After 2006, a series of technical and operational
problems arose. In the event, the project closed without delivering a functioning computerized Treasury system.
Some intermediate outputs included legal and regulatory instruments needed for implementing the TMIS, but
there were also delays in adopting these instruments.
The three main factors negatively affecting Treasury modernization were: (i) the lack of technical and managerial
capacity to design and manage a complex TMIS contract and the business re-engineering requirements of
    Treasury modernization; (ii) internal resistance to reform from those with vested interests in the existing system
    and the flexibility and informality that it facilitated; and (iii) differences in perspectives regarding system
    requirements across institutions and within the Ministry of Finance. Internal resistance led to the vendor being
    impeded in carrying out its work. Moreover the vendor was not paid for invoices submitted, and has revoked MoF
    access to any of the systems in development of the TMIS. GTAC’s inability to mitigate these circumstances
    contributed to the non-achievement of the objective (see Section 8b below).


5. Efficiency:

    No economic or financial analysis was conducted, either at appraisal or at closure. The ICR states that because
    GTAC is a technical assistance (TA) project, no cost-benefit analysis was undertaken at appraisal (although all
    investment loans including TA projects are expected to conduct quantitative analysis, either cost benefit or cost
    effectiveness). Given that a functioning TMIS was not delivered, the investment of US$5.5 million (68.9 percent
    of the project costs) under Component 2 was not an efficient use of funds. There are other indications of low
    efficiency, including the fact that a project that was expected to be implemented in five-and-a-half years had to be
    extended for another 5 years due to significant operational and administrative inefficiencies (the delays were
    mostly related to procurement issues involving the TMIS -- see Sections 8b, 9b and 11b below).

    Efficiency is rated negligible.


a. If available, enter the Economic Rate of Return (ERR)/Financial Rate of Return (FRR) at appraisal and the
   re-estimated value at evaluation :

                                 Rate Available?                         Point Value                        Coverage/Scope*

    Appraisal                         No
    ICR estimate                      No
                                       * Refers to percent of total project cost for which ERR/FRR was calculated.



6. Outcome:

    Objectives are substantially relevant, while relevance of design is rated modest given the absence of clear links
    between inputs, outputs, and outcomes. Efficacy of the first sub-objective is rated modest. Although a range of
    outputs were delivered, little evidence is presented to show that these resulted in strengthened capacity. Outputs
    related to the second sub-objective were only partially delivered, and the project closed without a management
    information system having been installed at the Treasury. Efficacy of the sub-objective is therefore rated
    negligible. Efficiency is also rated negligible, since no quantitative analysis was attempted, and there were major
    operational and administrative inefficiencies contributing to a five-year delay in completion. Outcome is assessed
    as unsatisfactory.

a. Outcome Rating: Unsatisfactory


7. Rationale for Risk to Development Outcome Rating:

    Although the ICR (p. 32) states that the resilience and institutionalization of key public sector reforms under
    Component 1 indicates high sustainability, there has already been backtracking in the results achieved, notably
    on politically sensitive reforms such as the de-politicization of the civil service. Government commitment to
    GSAC reforms, apparently strong at the outset has diminished according to the GSAC ICR that rated the
    adjustment operation's performance as moderately unsatisfactory.

    On balance, given that the project achievements are limited, the risk to development outcome is negligible to low.


  a. Risk to Development Outcome Rating : Negligible to Low

8. Assessment of Bank Performance:
a. Quality at entry:

   GTAC preparation was grounded in diagnostic work, partly financed by a PHRD grant that was associated
   with preparing the GSAC program. Government ownership was considered to be strong. The ICR states that
   the GTAC results framework, its scope and objectives were considered by a Quality at Entry Review, which
   rated project preparation as Highly Satisfactory (ICR, p. 17).

   There were, however, major shortcomings in Quality at Entry. As described in Section 3b, almost all the
   project's design was focused on the needs of Component 1, and overlooked what was required to implement
   Treasury modernization. Preparatory work on the Treasury modernization component was only undertaken
   after the project became effective in August 2003, and the TMIS design reports were finally completed at the
   end of 2006, more than three years after effectiveness. There is no evidence that an assessment of the
   change management implications of Treasury automation had been undertaken to identify the winners and
   losers, reform champions and resistors and to adjust institutional arrangements to address implementation
   risks (ICR, p. 33). Indeed, implementation arrangements were unsuited to TMIS installation, which requires
   clear lines of vertical accountability to ensure prompt and authoritative decision-making. These design
   shortcomings led to significant delays in launching the TMIS procurement and undermined effective TMIS
   contract management. Furthermore, the M&E framework lacked indicators to monitor the performance of the
   Treasury modernization and provided no guidance on the TMIS's functional scope. These weaknesses in
   preparation contributed to the need for four extensions of the project closing date, and resulted in the
   negligible efficacy of the second sub-objective.

   In addition, there was no efficiency analysis at Appraisal, and M&E design was weak (see Section 10a
   below).


  Quality-at-Entry Rating:                     Unsatisfactory

b. Quality of supervision:

   GTAC benefitted from intense supervision in the early years of implementation (14 Implementation Status
   Reports were filed in the two years between effectiveness and the political interruptions in 2005). These
   missions were complemented by video conference consultations. During the initial stages of implementation,
   supervision covered both Components 1 and 2 of the GTAC, and also the parallel GSAC. By the mid-term
   review in 2009, activities under Component 1 had been largely completed. Supervision from then on focused
   exclusively on Component 2 and became more intense as problems arose in Treasury modernization,
   especially during the last two years of implementation.
   The Bank maintained an appropriate mix of technical skills on the team throughout implementation. In
   particular, during the difficulties associated with the TMIS procurement, contracting and subsequent
   implementation, the team included specialists in the area of Treasury reform, financial management
   information systems and procurement of IT systems. Recognizing the challenges in installing this system, and
   those posed by broader governance concerns, the Bank, with support from bilateral partners under a parallel
   capacity building project, fielded a resident TTL in the country office from September 2011 to March 2013.
   After this assignment was terminated, task leadership reverted to headquarters.
   The ICR identifies no issues with regard to supervision of fiduciary compliance (see Section 11b below).

   There were, however, a number of significant shortcomings in the quality of supervision.

   First, despite intense supervision in the last two years of implementation, the team was unsuccessful in
   resolving the implementation problems related to Treasury modernization. The Task Team Leader (TTL)
   organized tripartite video conferences between the Bank, MOF and vendor every three weeks to track
   implementation progress in an effort to resolve issues. The Bank made repeated efforts to help the MOF and
   TMIS vendor come to an agreement on the TMIS functional and customization requirements. Aide Memoires
   provided detailed assessments of the implementation challenges and clear recommendations on solutions.
   Nonetheless, in December 2013, four years after contract signature, MOF cancelled the contract.

   Second, Bank staff changed frequently over the ten-and-a-half-year project implementation period. There
   were four country managers and six task team leaders, which inevitably affected continuity.

   Third, Implementation Status Reports (ISR) ratings do not accurately reflect the situation on the ground. ISRs
   continued to rate 'Implementation Progress' in the satisfactory range from 2003 to June 2008, except once in
   June 2004. Progress towards achieving the Development Objectives is rated in the satisfactory range
   throughout, until the end of December 2011.

   Fourth, the project could have been restructured to address the design flaws in Component 2 and correct the
   weaknesses in the M&E framework. Stronger links could have been forged between inputs, outputs,
   intermediate outcomes and final outcomes. Relevant indicators, targets and a timeline for measurement could
   have been specified. Instead, the deficiencies in the M&E framework remained unaddressed (see Section
   10b below). The project team informed IEG that the Bank had approached the Government with a view to
   revising the framework, but the Government did not request any such revision.

   Fifth, there could have been greater clarity over TMIS specifications during procurement. Insufficient weight
   was placed on the need for, and delivery of, technical advice to the Ministry of Finance (MoF) on TMIS design
   and contract management. The Bank team could have done more to ensure that MoF had adequate access
   to a technical specialist embedded in the Ministry with experience on Treasury modernization and automation
   to support decision making throughout TMIS implementation and design. An international advisor was
   contracted to provide this support, but was insufficiently engaged in the discussions within the MoF to guide
   the Authorities in managing a complex ITC contract and relations with the vendor.



  Quality of Supervision Rating :              Unsatisfactory

  Overall Bank Performance Rating :            Unsatisfactory


9. Assessment of Borrower Performance:

a. Government Performance:

   The ICR reports that the Government showed commitment during preparation of the GTAC. Though the
   performance of Government institutions was affected by changes in the aftermath of the 2005 and 2010
   revolutions, the Government managed to deliver some governance reforms with support from both GSAC and
   GTAC. There was backsliding, however (as mentioned in Section 7). The broad direction and institutional
   framework created by the reforms under Component 1 have been mostly sustained. However, there were
   significant shortcomings related to the Treasury modernization activities. The Ministry of Finance (MoF)
   resisted moving forward on the Treasury component over several years. Those with vested interest in the
   manual system and the flexibility it offered did not want the Treasury component to happen, and the
   Government was not able to resolve the situation. This severely affected Project outcomes and continues to
   pose a risk to improving the quality of governance and to promoting the voice of the people. The Government
   could also have done more to facilitate a more productive relationship with the vendor.


  Government Performance Rating                             Moderately Unsatisfactory

b. Implementing Agency Performance:

   The Ministry of Finance (MoF) was the lead implementing agency for Component 1 and the sole
   implementing agency for Component 2. There were frequent changes in MoF management during the course
   of implementation, with six Ministers of Finance, four State Secretaries and five heads of Treasury between
   2010 (when the TMIS vendor began activities) and project closure at the end of 2013. These changes
   adversely affected the management of a complex Treasury modernization process. There were delays in
   decision making as managers had to be brought up to speed on project design and implementation issues.
   This problem was compounded by lack of familiarity with Bank procedures. Protracted procurement
   procedures and time-consuming management processes requiring heavy involvement of senior officials
   further contributed to delays.

   Two particular shortcomings in implementing agency performance stand out. First, the MoF was slow to
   agree on and implement the institutional reforms needed to support the Treasury modernization, notably the
   unified Chart of Accounts (COA) and the requirements for the Treasury Single Account (TSA) interaction with
   the banking system. Second, MoF did not clearly articulate its expectations of the TMIS at the start of
   implementation, and subsequently changed system requirements. This was partly due to differing
   expectations within the Ministry and the lack of an adequate decision making structure to resolve differences
   in opinion. Both of these shortcomings reflect the Ministry’s limited technical and managerial capacity and its
   inexperience in dealing with complex Treasury modernization. MoF recognized its limited capacity in this area
   and established an in-house IT organization to develop solutions that were outside the capabilities of regular
   MoF staff. However, this proved insufficient to address the technical and change management requirements.

   Opposition to Treasury modernization from within MoF also contributed to delays and difficulties in reaching
   agreement with the vendor. When many high level officials most critical of the modernization process were
   replaced starting in late 2012, the prospects for successful implementation began to improve. However, due
   to the previously difficult operating environment, the vendor was not responsive to the improved situation
   (ICR, p. 37).


  Implementing Agency Performance Rating :                    Unsatisfactory

  Overall Borrower Performance Rating :                       Unsatisfactory



10. M&E Design, Implementation, & Utilization:

a. M&E Design:

   M&E design was weak. Although GTAC was approved to support measures under GSAC, and the GTAC results
   framework should have been clearly aligned to GSAC's policy framework, the framework set out in the PAD did
   not include a results chain, and there were no. clear links between project outputs, intermediate outcomes, and
   final outcomes; nor were there relevant outcome indicators and targets. The PAD also did not specify M&E
   arrangements to collect, analyze or to report data to provide decision makers with key information on progress
   towards the objectives. There was no discussion of baseline analysis. The PAD also did not include the
   monitoring framework with annual targets, which is usually presented in an annex, but was not required at the
   time; (however, it should have been retrofitted during implementation). The 12 listed Key Performance Indicators
   are mostly output indicators. In addition, there are 30 output indicators specified as such, but no plan as to how or
   how frequently to measure them. The data collection strategy includes "surveys of households, firms and public
   officials." However, there is no information on how many surveys or what methodology would be used, or what
   information would be expected from them.

   The use of public perceptions of transparency, responsiveness and integrity of the public sector as an outcome
   indicator presents problems of attribution since a wide range of factors outside the project would affect those
   perceptions. Attribution problems also arise due to fact that GSAC and GTAC were designed as parallel
   operations. Component 1 indicators were monitored by joint GSAC and GTAC teams, focusing on the
   Government’s progress in achieving GSAC triggers. Alignment of the M&E frameworks for the two operations
   makes it difficult to distinguish which results can be attributed to each.

   There was no monitoring framework for Treasury modernization, the largest of the two components in terms of
   value. M&E was to be restricted to one indicator (“computerized Treasury system implemented”), and lacked
   intermediate indicators.

b. M&E Implementation:

   The poor design of M&E contributed to deficient implementation. No baseline data were obtained. Measuring
   outcome achievement were to have relied on the use of periodic surveys of stakeholders of households, firms,
   and public officials to assess perceptions about transparency, responsiveness, and integrity of the public sector.
   However, these surveys were not undertaken. Monitoring of the indicators related to Component 1 ceased
   following the mid-term review in 2009, by which time most of the Component 1 activities had been completed.
   Consequently, it was not possible to assess the status of these indicators at project closure.

   The shortcomings in M&E design were noted during the mid-term review and in several subsequent supervision
   reports (indeed, the need to revise results indicators still featured in supervision reports as late as 2013).
   However, no action was taken. Perhaps the most obvious missed opportunity was the 2009 restructuring
   undertaken to align the PDO text in the PAD with that in the legal agreement as part of a Bank-wide exercise.
   Other opportunities arose during subsequent project extensions.
c. M&E Utilization:
     No information is provided in the ICR on M&E utilization.

M&E Quality Rating: Negligible




11. Other Issues

a. Safeguards:

    There were no safeguards policies triggered by this project, which was classified as Category "C" for
    Environmental Assessment purposes.


b. Fiduciary Compliance:

    The ICR (p. 24) reports that no fiduciary compliance issues arose during implementation, and fiduciary ratings in
    supervision reports were mostly satisfactory. The ICR does not provide information on timeliness of audits.

    Deficiencies in terms of proper specification of the TMIS led to delays that had implications for procurement,
    contracting and contract implementation. As there were no detailed specifications, there was no proper basis for
    estimating the costs of software and related hardware. These factors delayed implementation of the Treasury
    Modernization component (mentioned in Section 9b under Implementing Agency Performance).


c. Unintended Impacts (positive or negative):
None

d. Other:



12. Ratings:                             ICR                IEG Review                    Reason for
                                                                                   Disagreement/Comments
                    Outcome: Moderately               Unsatisfactory         The Project's design was weak,
                             Unsatisfactory                                  especially the results chain, there were
                                                                             major shortcomings in the achievement
                                                                             of outcomes, especially with respect to
                                                                             the second objective. There was no
                                                                             quantitative efficiency analysis and
                                                                             there were major operational and
                                                                             administrative inefficiencies.
         Risk to Development High                     Negligible to Low
                    Outcome:

            Bank Performance: Moderately              Unsatisfactory         There were major shortcomings in both
                              Unsatisfactory                                 Quality at Entry and Quality of
                                                                             Supervision. with regard to the
                                                                             preparation and implementation of the
                                                                             Treasury Modernization sub-objective.
                                                                             In addition, there were frequent
                                                                             changes in project staff, inaccurate
                                                                             ratings in supervision reports, and
                                                                             missed opportunities to restructure and
                                                                             address design flaws.
      Borrower Performance : Moderately               Unsatisfactory         Major shortcomings included
                             Unsatisfactory                                  substantial resistance over several
                                                                             years to proceeding with Treasury
                                                                              modernization, inability to resolve
                                                                              conflicts with vested interests, and lack
                                                                              of effort in facilitating a more productive
                                                                              relationship with the TMIS vendor.
                Quality of ICR:                             Unsatisfactory

NOTES:
- When insufficient information is provided by the Bank
  for IEG to arrive at a clear rating, IEG will downgrade
  the relevant ratings as warranted beginning July 1,
  2006.
- The "Reason for Disagreement/Comments" column
  could cross-reference other sections of the ICR
  Review, as appropriate.

13. Lessons:

    IEG draws the following lessons from the preparation and implementation of this project:

         It is important that technical assistance operations accompanying DPOs have their own clearly specified
          and measurable objectives. Although Development Policy Operations (DPOs) may need accompanying
          technical assistance projects, issues can arise due the differences in the time needed to achieve expected
          results. The time frame for DPO preparation is often driven by financing requirements and the
          Government's readiness to complete prior actions. Technical assistance operations tend to include a
          range of interventions across sectors and thematic issues requiring more complex, multi-institutional
          implementation arrangements. This incompatibility in time frames may make it inappropriate for the
          technical assistance project to share the DPO's objectives.
         Identifying and understanding the motivations of the potential winners and losers of a project activity (in
          this case winners and losers within the Ministry of Finance), is important at the preparation stage.
          Otherwise, political resistance to change can thwart implementation and project outcomes. It is equally
          necessary to assess accurately the implementing agency's technical capacity to implement complex
          systems, and to incorporate activities in design to address identified weaknesses.
         Accurate ratings in supervision reports help to identify in a timely manner challenges faced by projects
          and undertake remedial measures. In this case, Implementation Status Report ratings did not accurately
          reflect the situation on the ground.
         Timely restructuring can assist in successful implementation and the achievement of outcomes. In this
          case, the project could advantageously have been restructured to address design flaws. A restructuring
          could have also corrected the weaknesses in the M&E framework, which lacked a valid results chain and
          relevant indicators.


14. Assessment Recommended?                  Yes      No




15. Comments on Quality of ICR:


    The ICR is candid but suffers from significant shortcomings. It does not follow the ICR Guidelines in several
    areas, in particular with regard to the Assessment of Outcomes. The ICR reports on results by component, and is
    more of a summary of outputs rather than a results-oriented discussion of outcomes. The fact that the PAD had
    a weak results framework, with hardly any outcome indicators nor targets may have contributed to this; however,
    the ICR should have noted it up front.

    There is confusion about the timing of the mid-term review (MTR). According to the Data Sheet, the MTR was
    scheduled for February 2009, but did not actually take place until March, 2012. On page 19 of the ICR, it is
    mentioned as having taken place in March, 2008.

    The ICR is long (30 pages) and much of the Section on the Achievement of Results by Component could have
    gone into Annex 2 (Outputs by Component). The ICR does not refer to any re-allocations of cancelled
    sub-components. There is little discussion of the financial management of the project. There is virtually no
    analysis of efficiency. More thorough proofreading would have been helpful, including doing a spell check on the
    cover page.

a.Quality of ICR Rating : Unsatisfactory
